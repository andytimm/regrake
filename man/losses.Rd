% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/losses.R
\name{losses}
\alias{losses}
\alias{equality_loss}
\alias{least_squares_loss}
\alias{inequality_loss}
\alias{kl_loss}
\title{Loss Functions for Regularized Survey Weighting}
\usage{
equality_loss(x, target)

least_squares_loss(x, target, diag_weight = 1)

inequality_loss(x, lower, upper)

kl_loss(x, target)
}
\arguments{
\item{x}{Numeric vector of values}

\item{target}{Numeric vector of target values}

\item{diag_weight}{Numeric scalar or vector of weights for each element (default 1)}

\item{lower}{Lower bound}

\item{upper}{Upper bound}
}
\value{
Vector of loss values

Numeric vector of absolute differences between x and target

Numeric vector of weighted squared differences between x and target

Numeric vector of KL divergence values. Returns Inf for non-positive inputs
and NA for NA/NaN inputs.
}
\description{
These functions implement different loss metrics for survey weight optimization:
\itemize{
\item equality_loss: Absolute difference for exact matching
\item least_squares_loss: Squared error loss
\item inequality_loss: Hinge loss for range/inequality constraints
\item kl_loss: Kullback-Leibler divergence
}
}
\details{
For KL divergence, both x and target must be positive.
Returns Inf for non-positive values and NA for NA/NaN inputs.
}
\section{Functions}{
\itemize{
\item \code{equality_loss()}: Absolute difference loss for exact matching constraints

\item \code{least_squares_loss()}: Squared error (least squares) loss

\item \code{inequality_loss()}: Inequality constraint loss

\item \code{kl_loss()}: Kullback-Leibler divergence loss

}}
\keyword{internal}
