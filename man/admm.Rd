% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/solver.R
\name{admm}
\alias{admm}
\title{ADMM solver for regularized survey weighting}
\usage{
admm(
  F,
  losses,
  reg,
  lam,
  control = list(),
  verbose = FALSE,
  bounds = NULL,
  bounds_method = "soft"
)
}
\arguments{
\item{F}{Design matrix (converted to sparse internally)}

\item{losses}{List of loss functions, each containing fn (loss function),
target (target values), prox (proximal operator), and optionally
lower/upper (bounds for inequality constraints)}

\item{reg}{Regularizer object with fn (regularization function) and
prox (proximal operator)}

\item{lam}{Regularization strength parameter}

\item{control}{List of control parameters: rho (ADMM penalty, default 50),
maxiter (max iterations, default 5000), eps_abs and eps_rel (convergence
tolerances, default 1e-5)}

\item{verbose}{Print convergence progress (default FALSE)}

\item{bounds}{Optional numeric vector of length 2 specifying (min, max) weight
bounds as ratios to uniform weight. Only used when bounds_method = "hard".}

\item{bounds_method}{Method for enforcing bounds: "soft" (via regularizer limit,
default) or "hard" (via bounded simplex projection).}
}
\value{
List containing f (final f vector), w (final weights), w_bar
(projected weights), w_tilde (regularized weights), y/z/u (dual variables),
and w_best (best solution found)
}
\description{
Implements the ADMM (Alternating Direction Method of Multipliers) algorithm for
solving regularized survey weighting problems. The algorithm minimizes a sum of loss
functions subject to simplex constraints and regularization.
}
\details{
The implementation uses sparse matrix operations and cached Cholesky factorization
for efficiency. Numerical stability is ensured through careful matrix conditioning
and damping.
}
